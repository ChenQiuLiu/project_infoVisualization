{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gloabl variable, which can be input at first, but in this example, they all be defined \n",
    "use_columns = ['train_energy(J)','no_datapoints','no_features','datatype','algorithm','RQ'] # must have\n",
    "digit_columns = ['train_energy(J)','no_datapoints','no_features'] # must have\n",
    "split_column = 'datatype' # may not have\n",
    "class_column = 'RQ' # may not have\n",
    "group_column = 'algorithm' # must have\n",
    "y_column = 'train_energy(J)'\n",
    "x_columns = ['no_datapoints','no_features','datatype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_num_str(x):\n",
    "    digit = \"\".join(list(filter(str.isdigit, x)))\n",
    "    return int(digit), x.strip(digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行这段代码之前，先运行gloabl variable代码块\n",
    "def load_data():\n",
    "    path = input(\"Please input the file path: \") # E:/项目数据集/project1_dataset.csv\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.loc[:,use_columns]\n",
    "    if split_column: # split the number and the string\n",
    "        df['type'] = df[split_column].map(lambda x:split_num_str(x)[1])\n",
    "        df['byte'] = df[split_column].map(lambda x:split_num_str(x)[0])\n",
    "        use_columns.append('type')\n",
    "        use_columns.append('byte')\n",
    "        digit_columns.append('byte')\n",
    "    return df # 返回预处理过后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the file path: E:/项目数据集/project1_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conbine_different_iterition(df):\n",
    "    y_choice = y_column # choose the columns\n",
    "    groupby_list = list(df.columns)\n",
    "    groupby_list.remove(y_choice)\n",
    "    iterition_group = df.groupby(groupby_list)[y_choice]\n",
    "    mean_iterition = iterition_group.mean()\n",
    "    var_iterition = iterition_group.var()\n",
    "    mean_iterition_df = mean_iterition.add_suffix(\"\").reset_index()\n",
    "    mean_iterition_df.rename(columns={y_column:y_column+'_mean'},inplace=True) # This can't be reuse\n",
    "    var_iterition_df = var_iterition.add_suffix(\"\").reset_index()\n",
    "    var_iterition_df.rename(columns={y_column:y_column+'_var'},inplace=True)\n",
    "    clean_data = pd.concat([mean_iterition_df,var_iterition_df['train_energy(J)_var']],axis=1)\n",
    "    digit_columns.remove(y_column)\n",
    "    for i in digit_columns:\n",
    "        clean_data[i] = clean_data[i].map(lambda x: float(x))\n",
    "        clean_data[i].astype(float)\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_datapoints           float64\n",
       "no_features             float64\n",
       "datatype                 object\n",
       "algorithm                object\n",
       "RQ                       object\n",
       "type                     object\n",
       "byte                    float64\n",
       "train_energy(J)_mean    float64\n",
       "train_energy(J)_var     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = conbine_different_iterition(df)\n",
    "clean_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = clean_data.groupby(class_column)\n",
    "# 当处理2.1和2.2时，返回的数据为按照算法顺序排列的相关系数列表\n",
    "# 当处理2.3是，返回的数据为两个（数据类型和位数）按照算法顺序排列的相关系数列表\n",
    "    # 先根据datatype算出每一个分类下的数据的 y_mean,y_var（六行df）\n",
    "    # 然后根据type列进行groupby，找出每一个group内部的byte列和y_mean的相关系数\n",
    "    # 然后根据byte列进行groupby，找出每一个group内部的type对y_mean的影响\n",
    "        # 将float看做是位数中的最小值，将int看做是位数中的最大值，若结果呈现正相关，则说明int行在此算法中比float更加增加运算能耗\n",
    "# 使用spearman相关系数分析数值和分类的相关性无法得出影响的具体结论，所以换\n",
    "result_dict = {\n",
    "    '2.1':[],  # no_datapoint_effect\n",
    "    '2.2':[],  # no_feature_effect\n",
    "    '2.31':[], # type effect\n",
    "    '2.32':[] # byte effect\n",
    "}\n",
    "avg_dict = {\n",
    "    '2.1':[],  # no_datapoint_effect\n",
    "    '2.2':[],  # no_feature_effect\n",
    "    '2.3':[], # type effect\n",
    "}\n",
    "algorithm_term = []\n",
    "\n",
    "for i in df_group:\n",
    "    target = i[0]\n",
    "    if target == '2.3':\n",
    "        type_effect = '2.31'\n",
    "        byte_effect = '2.32'\n",
    "        data = (i[1]).loc[:,['train_energy(J)_mean','train_energy(J)_var','datatype','type','byte','algorithm']] # 选中五列（y列，datatype列）\n",
    "        data_groupby_algorithm = data.groupby('algorithm')\n",
    "        for each_algorithm_data in data_groupby_algorithm: # 每个数据类型下的\n",
    "            data_groupby_type = each_algorithm_data[1].groupby('type')\n",
    "            data_groupby_byte = each_algorithm_data[1].groupby('byte')\n",
    "            type_register = []\n",
    "            byte_register = []\n",
    "            for each_type_data in data_groupby_type: # 找的是byte和y的相关性\n",
    "                type_register.append((each_type_data[1])['byte'].corr((each_type_data[1])['train_energy(J)_mean']))\n",
    "            (result_dict[type_effect]).append(np.mean(type_register))\n",
    "            type_register_x = []\n",
    "            type_register_y = []\n",
    "            for each_byte_data in data_groupby_byte:\n",
    "                if len(each_byte_data[1]) != 1:\n",
    "                    regisit_df = each_byte_data[1]\n",
    "                    regisit_df['type'] = regisit_df['type'].map({'float':2,'int':1})\n",
    "                    #type_register.append((each_byte_data[1])['type'].corr((each_byte_data[1])['train_energy(J)_mean']))\n",
    "                    type_register_x += list((each_byte_data[1])['type'])\n",
    "                    type_register_y += list((each_type_data[1])['train_energy(J)_mean'])\n",
    "                else:\n",
    "                    continue\n",
    "            (result_dict[byte_effect]).append(pd.Series(type_register_x).corr(pd.Series(type_register_y)))\n",
    "            byte_register = []\n",
    "            (avg_dict[target]).append(np.mean((each_algorithm_data[1])['train_energy(J)_var']))\n",
    "    elif target == '2.2':\n",
    "        data = (i[1]).loc[:,['train_energy(J)_mean','train_energy(J)_var','algorithm','no_features']] # 选中四列\n",
    "        data_groupby_algorithm = data.groupby('algorithm')\n",
    "        for each_algorithm_data in data_groupby_algorithm:\n",
    "            algorithm_term.append(each_algorithm_data[0])\n",
    "            (result_dict[target]).append((each_algorithm_data[1])['no_features'].corr((each_algorithm_data[1])['train_energy(J)_mean']))\n",
    "            (avg_dict[target]).append(np.mean((each_algorithm_data[1])['train_energy(J)_var']))\n",
    "    elif target == '2.1':\n",
    "        data = (i[1]).loc[:,['train_energy(J)_mean','train_energy(J)_var','algorithm','no_datapoints']] # 选中四列\n",
    "        data_groupby_algorithm = data.groupby('algorithm')\n",
    "        for each_algorithm_data in data_groupby_algorithm:\n",
    "            (result_dict[target]).append((each_algorithm_data[1])['no_datapoints'].corr((each_algorithm_data[1])['train_energy(J)_mean']))\n",
    "            (avg_dict[target]).append(np.mean((each_algorithm_data[1])['train_energy(J)_var']))\n",
    "    \n",
    "            \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2.1': [0.8221057652019632,\n",
       "  -0.38702616155213754,\n",
       "  0.7205491718194771,\n",
       "  0.15611440744738872,\n",
       "  0.13990358781906234,\n",
       "  0.9052516948572668,\n",
       "  0.6687892183022692],\n",
       " '2.2': [0.18286507107382075,\n",
       "  0.6131875842062663,\n",
       "  0.3880692615210869,\n",
       "  0.06166137894531045,\n",
       "  0.21475163446238538,\n",
       "  0.634083348489993,\n",
       "  0.8399858392645699],\n",
       " '2.31': [0.389156979066436,\n",
       "  -0.46117715396425907,\n",
       "  0.2559146412169166,\n",
       "  -0.2829521055827869,\n",
       "  -0.0004597556072427067,\n",
       "  0.2213939724869253,\n",
       "  0.42608143184820535],\n",
       " '2.32': [-0.4613312223285261,\n",
       "  -0.6548290407462889,\n",
       "  -0.6776156214972892,\n",
       "  0.08850266178039184,\n",
       "  0.676603652013143,\n",
       "  0.02895459496969049,\n",
       "  -0.4853548983855736]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict # 按照算法排序, 2.31是数据的type的影响，大于0即为float促进y值上升，小于零即为int型促进y值上升"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2.1': [1.6175762093044437,\n",
       "  0.8084858543352379,\n",
       "  0.010192904705615161,\n",
       "  0.0014705539589917763,\n",
       "  0.0007650236472635585,\n",
       "  4.487831714651066,\n",
       "  2.0615220202111137],\n",
       " '2.2': [7.9001969979445,\n",
       "  0.8143249924024655,\n",
       "  0.014866978072913473,\n",
       "  0.0007008922110172212,\n",
       "  0.00672283884489457,\n",
       "  91.05453365141429,\n",
       "  0.16341952915034438],\n",
       " '2.3': [8.135646636833442,\n",
       "  2.106609953408848,\n",
       "  0.026689434193996678,\n",
       "  0.0014147765060318143,\n",
       "  0.0008196535090276577,\n",
       "  169.14244865660655,\n",
       "  1.8134900190570338]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_dict# 每种算法对应的平均方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AdaBoost',\n",
       " 'Bagging Classifier',\n",
       " 'Decision Tree',\n",
       " 'KNN',\n",
       " 'Multinomial NB',\n",
       " 'Random Forest',\n",
       " 'SVM']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_term # 算法顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
